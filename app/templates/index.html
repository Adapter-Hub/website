{% extends 'base.html' %}

{% block title %} A central repository for pre-trained adapter modules {% endblock %}

{% block header %}
    <div class="row">
        <div class="text-light col-md-9">
            <p class="highlight-text mt-md-3">
                <span class="highlight">AdapterHub</span>
                is a <span class="highlight">central repository</span><br class="d-none d-lg-inline">
                for pre-trained <span class="highlight">adapter modules</span>.
            </p>

            <div id="IndexButtonRow" class="rounded mb-3">
                <a class="btn"
                   href="{{ url_for('main.explore_tasks') }}">
                    <div>
                        <i class="fas fa-binoculars"></i>
                    </div>
                    Explore
                </a>
                <a class="btn d-none d-sm-inline-block"
                   href="{{ config.CONTRIBUTING_URL }}">
                    <div>
                        <i class="fas fa-upload"></i>
                    </div>
                    Upload
                </a>
                <a class="btn"
                   href="{{ config.DOCUMENTATION_URL }}">
                    <div>
                        <i class="fas fa-book"></i>
                    </div>
                    Docs
                </a>
                <a class="btn d-none d-lg-inline-block"
                   href="https://github.com/adapter-hub">
                    <div>
                        <i class="fab fa-github"></i>
                    </div>
                    GitHub
                </a>
                <a class="btn"
                   href="https://github.com/adapter-hub">
                    <div>
                        <i class="fas fa-scroll"></i>
                    </div>
                    Paper
                </a>
            </div>
            <pre class="text-white py-2 px-3 mt-4">pip install git+https://github.com/adapter-hub/adapter-transformers.git</pre></p>
        </div>
        <div class="col-sm-3 text-right d-none d-md-block">
            <img src="{{ url_for('static', filename='adapter-bert.png') }}" height="275"/>
        </div>
    </div>
{% endblock %}

{% block content %}

    <section>
        <div class="row">
            <div class="card col-md mt-md-3 mx-3 px-0 px-md-2 bg-light border-0">
                <div class="card-body">
                    <h5 class="card-title">Adapters ü§ñ</h5>
                    <p class="card-text">Adapters are a small amount of newly introduced weights within each layer of a transformer model such as BERT or RoBERTa. Training Adapters performs on-par with full fine-tuning the model, while only requiring as little as 1MB of storage space per task. </p>
                </div>
            </div>

            <div class="card col-md mx-3 ml-md-0 mr-md-3 mr-lg-0 mt-3 px-0 px-md-2 bg-light border-0">
                <div class="card-body">
                    <h5 class="card-title">Modular, Composable, Extensible üîß</h5>
                    <p class="card-text"> Adapters are encapsuled within layers, making the  representations  compatible. They can thus be stacked, composed or similarly modified, opening up many research directions. </p>
                </div>
            </div>

            <div class="card col-lg mx-3 mt-3 px-0 px-md-2 bg-light border-0">
                <div class="card-body">
                    <h5 class="card-title">Built on HuggingFace Transformers üöÄ</h5>
                    <p class="card-text">AdapterHub builds on the <a href=https://github.com/huggingface/transformers target="_blank">HuggingFace transformers</a> framework requiring as little as two additional lines of code to train adapters for a downstream task.</p>
                </div>
            </div>
        </div>
    </section>

    <section>
        <div class="row">
            <div class="col col-lg-12">
                <h1>Quickstart üî•</h1>
            </div>
        </div>
        <div class="row mt-3">
            <div class="col col-12 col-md-4">
                <div class="list-group flex-md-column flex-row" role="tablist">
                    <a href="#quickstartInference" class="list-group-item list-group-item-action active" data-toggle="tab" role="tab" aria-controls="quickstartInference" aria-selected="true">
                        Inference
                    </a>
                    <a href="#quickstartTraining" class="list-group-item list-group-item-action" data-toggle="tab" role="tab" aria-controls="quickstartTraining" aria-selected="true">
                        Training
                    </a>
                </div>
            </div>

            <div class="tab-content col col-12 col-md-8 mt-4 mt-md-0">
                <div class="tab-pane fade show active" id="quickstartInference" role="tabpanel">
                    <h3 class="mt-0">Load an Adapter for Inference üèÑ</h3>
                    <p>Loading existing adapters from our repository is as simple as adding one additional line of code:</p>
                    <pre class="code p-3">model = AutoModel.from_pretrained('roberta-base')
model.load_adapter('sst', load_head=True)</pre>
                    <p>The <a href="">SST adapter</a> is light-weight: it is only 3MB! At
                        the same time, it achieves <a href="">results</a> that are on-par with fully fine-tuned BERT.
                        We can now leverage SST adapter to predict the sentiment of sentences:</p>
                    <pre class="code p-3" id="QuickstartInferenceMore">
tokenizer = AutoTokenizer.from_pretrained('roberta-base')
tokens = tokenizer.tokenize("AdapterHub is awesome!")
input_tensor = torch.tensor([
    tokenizer.convert_tokens_to_ids(tokens)
])

outputs = model(
    input_tensor,
    adapter_tasks=['sst'],
    task='sst'
)</pre>
                </div>

                <div class="tab-pane fade" id="quickstartTraining" role="tabpanel">
                    <h3 class="mt-0">Train an Adapter üèãÔ∏èÔ∏è</h3>
                    <p>...</p>
                </div>
            </div>
        </div>
    </section>

    <section>
        <h1>Citation üìù</h1>
        <pre class="p-4 code">
@article{pfeiffer2020AdapterHub,
    title={AdapterHub},
    author={Jonas Pfeiffer, 
            Andreas R\"uckl\'{e}, 
            Clifton Poth, 
            Aishwarya Kamath,  
            Ivan Vuli\'{c}, 
            Sebastian Ruder, 
            Kyunghyun Cho, 
            Iryna Gurevych},
    journal={ArXiv},
    year={2020}
}</pre>
    </section>


{% endblock %}
